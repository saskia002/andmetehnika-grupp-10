services:
    mongodb:
        image: mongo:8
        container_name: mongodb
        restart: always
        ports:
            - "27017:27017"
        environment:
            MONGO_INITDB_ROOT_USERNAME: root
            MONGO_INITDB_ROOT_PASSWORD: root
        volumes:
            - mongo_data:/data/db

    mongodb-init:
        image: python:3.12
        container_name: mongodb-init
        depends_on:
            - mongodb
        volumes:
            - ./mongo:/mongo # contains init.py, seed.py
            - ../requirements.txt:/requirements.txt:ro
        working_dir: /mongo
        command: >
            bash -c "
              echo 'Installing dependencies...' &&
              pip install -r /requirements.txt &&
              echo 'Waiting for MongoDB...' &&
              sleep 10 &&
              python init.py &&
              python seed.py
            "

    airflow-db:
        container_name: airflow-db
        image: postgres:16.4
        depends_on:
            - mongodb-init
        environment:
            POSTGRES_USER: airflow
            POSTGRES_PASSWORD: airflow
            POSTGRES_DB: airflow
            PGUSER: airflow
            PGPASSWORD: airflow
            PGDATABASE: airflow
        ports:
            - "5432:5432"
        volumes:
            - ./pgdata_airflow:/var/lib/postgresql/data
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U airflow"]
            interval: 10s
            retries: 5
        restart: always

    # --- Airflow Webserver ---
    airflow-webserver:
        image: apache/airflow:2.8.1
        container_name: airflow-webserver
        command: webserver
        environment:
            AIRFLOW__CORE__EXECUTOR: LocalExecutor
            AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
            AIRFLOW__CORE__LOAD_EXAMPLES: "false"
            AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth"
            _PIP_ADDITIONAL_REQUIREMENTS: "apache-airflow-providers-mongo pymongo yfinance==0.2.66 multitasking==0.0.11"
        ports:
            - "8080:8080"
        volumes:
            - ./dags:/opt/airflow/dags
            - ./logs:/opt/airflow/logs
        depends_on:
            - airflow-init
            - airflow-db
            - mongodb-init
        restart: always

    # --- Airflow Scheduler ---
    airflow-scheduler:
        image: apache/airflow:2.8.1
        container_name: airflow-scheduler
        command: scheduler

        environment:
            AIRFLOW__CORE__EXECUTOR: LocalExecutor
            AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
            AIRFLOW__CORE__LOAD_EXAMPLES: "false"
            _PIP_ADDITIONAL_REQUIREMENTS: "apache-airflow-providers-mongo pymongo yfinance==0.2.66 multitasking==0.0.11 requests"
            CLICKHOUSE_USER: etl
            CLICKHOUSE_PASSWORD: pass
        volumes:
            - ./dags:/opt/airflow/dags
            - ./logs:/opt/airflow/logs
        depends_on:
            - airflow-init
            - airflow-db
            - mongodb-init
        restart: always

    # --- Airflow DB initialization & user setup ---
    airflow-init:
        image: apache/airflow:2.8.1
        container_name: airflow-init
        entrypoint: /bin/bash
        command:
            - -c
            - |
                airflow db init
                airflow users create \
                  --username airflow \
                  --password airflow \
                  --firstname Admin \
                  --lastname User \
                  --role Admin \
                  --email admin@example.com
        environment:
            AIRFLOW__CORE__EXECUTOR: LocalExecutor
            AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
            _PIP_ADDITIONAL_REQUIREMENTS: "apache-airflow-providers-mongo pymongo yfinance==0.2.66 multitasking==0.0.11"
        volumes:
            - ./dags:/opt/airflow/dags
            - ./logs:/opt/airflow/logs
        depends_on:
            - airflow-db
            - mongodb-init
        restart: "no"

    clickhouse:
        image: clickhouse/clickhouse-server:24.8
        container_name: clickhouse
        restart: always
        ports:
            - "8123:8123" # HTTP
            - "9000:9000" # TCP
        environment:
            - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
        volumes:
            - clickhouse_data:/var/lib/clickhouse
            - ./clickhouse/init:/docker-entrypoint-initdb.d:ro
        depends_on:
            - mongodb-init

  # --- Airflow DB initialization & user setup ---
  airflow-init:
    image: apache/airflow:2.8.1
    container_name: airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db init
        airflow users create \
          --username airflow \
          --password airflow \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      _PIP_ADDITIONAL_REQUIREMENTS: "apache-airflow-providers-mongo pymongo yfinance==0.2.66 multitasking==0.0.11"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
    depends_on:
      - airflow-db
    restart: "no"

  # --- Clickhouse initialization & user setup ---
  clickhouse:
    image: clickhouse/clickhouse-server:24.8
    container_name: clickhouse
    restart: always
    ports:
      - "8123:8123"  # HTTP
      - "9000:9000"  # TCP
    environment:
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./clickhouse/init:/docker-entrypoint-initdb.d:ro


  # --- dbt initialization & user setup ---
  dbt:
    # dbt container for building and testing ClickHouse models
    build:
      context: ./dbt-docker              # Build context is the current directory
      dockerfile: Dockerfile   # Use the Dockerfile in this directory to build dbt image
    container_name: dbt
    depends_on:
      - clickhouse      # Ensure ClickHouse starts before dbt
    volumes:
      - ./data:/var/lib/clickhouse # Shared folder for input files
      - ./sql:/sql                                  # Shared SQL scripts
      - ./mongo:/dbt                                  # Mount local dbt project directory
    working_dir: /dbt          # Set dbt project directory as the working directory
    tty: true                  # Keep container running for interactive dbt commands


volumes:
    mongo_data:
    clickhouse_data:
